{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095ba7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4396a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_run(base_path):\n",
    "    base_path = Path(base_path)\n",
    "    run_dirs = [d for d in base_path.glob(\"run_*\") if d.is_dir()]\n",
    "    if not run_dirs:\n",
    "        raise FileNotFoundError(f\"No run directories found in {base_path}\")\n",
    "    return max(run_dirs, key=lambda d: datetime.strptime(d.name.replace(\"run_\", \"\"), \"%Y-%m-%d_%H-%M-%S\"))\n",
    "\n",
    "def load_monitor_file(monitor_dir):\n",
    "    monitor_dir = Path(monitor_dir)\n",
    "    csv_file = list(monitor_dir.glob(\"*.csv\"))\n",
    "    if not csv_file:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {monitor_dir}\")\n",
    "    return pd.read_csv(csv_file[0], skiprows=1)\n",
    "\n",
    "def calculate_metrics(df):\n",
    "    rewards_df = df['r']\n",
    "    total_timesteps = df['l'].sum()\n",
    "    return {\n",
    "        'mean': rewards_df.mean(),\n",
    "        'std': rewards_df.std(),\n",
    "        'median': rewards_df.median(),\n",
    "        'max': rewards_df.max(),\n",
    "        'success': np.mean(rewards_df >= 475) * 100,\n",
    "        'timesteps': total_timesteps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81927fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(__file__).resolve().parents[2] if '__file__' in globals() else Path.cwd().parents[1]\n",
    "docs = root / \"documentation\" / \"cartpole\"\n",
    "\n",
    "ppo_run = find_latest_run(docs / \"ppo-cartpole\")\n",
    "dqn_run = find_latest_run(docs / \"dqn-cartpole\")\n",
    "\n",
    "ppo_df = load_monitor_file(ppo_run / \"monitor\")\n",
    "dqn_df = load_monitor_file(dqn_run / \"monitor\")\n",
    "\n",
    "comparison_dir = docs / \"comparison\" / f\"ppo_vs_dqn_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "graphs_dir = comparison_dir / \"graphs\"\n",
    "graphs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f34189",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_metrics = calculate_metrics(ppo_df)\n",
    "dqn_metrics = calculate_metrics(dqn_df)\n",
    "improvement = (ppo_metrics['mean'] - dqn_metrics['mean']) / dqn_metrics['mean'] * 100\n",
    "t_stat, p_val = stats.ttest_ind(ppo_df['r'], dqn_df['r'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e81836cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(ppo_metrics, dqn_metrics, out):\n",
    "    labels = [\"Mean\", \"Median\", \"Max\", \"Success Rate (%)\"]\n",
    "    ppo_vals = [ppo_metrics['mean'], ppo_metrics['median'], ppo_metrics['max'], ppo_metrics['success']]\n",
    "    dqn_vals = [dqn_metrics['mean'], dqn_metrics['median'], dqn_metrics['max'], dqn_metrics['success']]\n",
    "    x = np.arange(len(labels)); w = 0.35\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.bar(x - w/2, ppo_vals, w, label='PPO', color='tab:orange')\n",
    "    plt.bar(x + w/2, dqn_vals, w, label='DQN', color='tab:blue')\n",
    "    plt.xticks(x, labels); plt.ylabel(\"Value\"); plt.title(\"Performance Metrics Comparison\")\n",
    "    plt.legend(); plt.grid(alpha=0.3, axis='y')\n",
    "    plt.savefig(out / \"metrics.png\", dpi=300, bbox_inches='tight'); plt.close()\n",
    "\n",
    "def plot_cumulative(ppo, dqn, out):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(np.cumsum(ppo['r']), label=\"PPO (Cumulative)\", color='tab:orange')\n",
    "    plt.plot(np.cumsum(dqn['r']), label=\"DQN (Cumulative)\", color='tab:blue')\n",
    "    plt.title(\"Cumulative Rewards Over Episodes (PPO vs DQN)\")\n",
    "    plt.xlabel(\"Episode\"); plt.ylabel(\"Total Reward\")\n",
    "    plt.legend(); plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out / \"cumulative.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_overlay_with_mean(ppo, dqn, out):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(ppo['r'].rolling(10).mean(), label=\"PPO (MA-10)\", color='tab:orange')\n",
    "    plt.plot(dqn['r'].rolling(10).mean(), label=\"DQN (MA-10)\", color='tab:blue')\n",
    "\n",
    "    plt.axhline(ppo['r'].mean(), color='orange', linestyle='--', alpha=0.5, label=f\"PPO Mean ({ppo['r'].mean():.1f})\")\n",
    "    plt.axhline(dqn['r'].mean(), color='blue', linestyle='--', alpha=0.5, label=f\"DQN Mean ({dqn['r'].mean():.1f})\")\n",
    "\n",
    "    plt.title(\"Moving Averages + Mean Reward Levels\")\n",
    "    plt.xlabel(\"Episode\"); plt.ylabel(\"Reward\")\n",
    "    plt.legend(); plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out / \"overlay_with_mean.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0909669",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_metrics(ppo_metrics, dqn_metrics, graphs_dir)\n",
    "plot_cumulative(ppo_df, dqn_df, graphs_dir)\n",
    "plot_overlay_with_mean(ppo_df, dqn_df, graphs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f187a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*PPO vs DQN Comparison*\n",
      "PPO Mean Reward: 217.80\n",
      "DQN Mean Reward: 69.37\n",
      "Improvement (PPO over DQN): 213.97%\n",
      "t-stat: 14.326, p-value: 0.0000000\n",
      "PPO Total Timesteps: 100,623\n",
      "DQN Total Timesteps: 100,100\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n*PPO vs DQN Comparison*\")\n",
    "print(f\"PPO Mean Reward: {ppo_metrics['mean']:.2f}\")\n",
    "print(f\"DQN Mean Reward: {dqn_metrics['mean']:.2f}\")\n",
    "print(f\"Improvement (PPO over DQN): {improvement:.2f}%\")\n",
    "print(f\"t-stat: {t_stat:.3f}, p-value: {p_val:.7f}\")\n",
    "print(f\"PPO Total Timesteps: {ppo_metrics['timesteps']:,}\")\n",
    "print(f\"DQN Total Timesteps: {dqn_metrics['timesteps']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5856d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_file = comparison_dir / \"summary.md\"\n",
    "with open(summary_file, \"w\") as f:\n",
    "    f.write(f\"# PPO vs DQN Comparison ({datetime.now():%Y-%m-%d %H:%M:%S})\\n\\n\")\n",
    "    f.write(f\"- PPO Mean Reward: **{ppo_metrics['mean']:.2f}**\\n\")\n",
    "    f.write(f\"- DQN Mean Reward: **{dqn_metrics['mean']:.2f}**\\n\")\n",
    "    f.write(f\"- Improvement (PPO over DQN): **{improvement:.2f}%**\\n\")\n",
    "    f.write(f\"- t-stat: {t_stat:.3f}\\n\")\n",
    "    f.write(f\"- p-value: {p_val:.9f}\\n\\n\")\n",
    "    f.write(\"## Training Details\\n\")\n",
    "    f.write(f\"- PPO Total Timesteps: {ppo_metrics['timesteps']:,}\\n\")\n",
    "    f.write(f\"- DQN Total Timesteps: {dqn_metrics['timesteps']:,}\\n\\n\")\n",
    "    f.write(f\"## Run Sources\\n\")\n",
    "    f.write(f\"- PPO run: {ppo_run}\\n\")\n",
    "    f.write(f\"- DQN run: {dqn_run}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
